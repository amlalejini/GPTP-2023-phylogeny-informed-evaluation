{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelimaries & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import itertools as it\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter as mpl_FuncFormatter\n",
    "from nbmetalog import nbmetalog as nbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from teeplot import teeplot as tp\n",
    "from tqdm import tqdm\n",
    "from scipy import stats as scipy_stats\n",
    "from statsmodels import stats as statsmodels_stats\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbm.print_metadata()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://osf.io/45b6h/download\", compression=\"gzip\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdigest = np.bitwise_xor.reduce(\n",
    "    pd.util.hash_pandas_object(df),\n",
    ")\n",
    "print(\"{:x}\".format(dfdigest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip out implementation-detail -opt suffixes\n",
    "df[\"EVAL_FIT_EST_MODE\"] = df[\"EVAL_FIT_EST_MODE\"].str.replace(\"-opt\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"EVAL_FIT_EST_MODE-EVAL_MODE\"] = (\n",
    "    df[\"EVAL_FIT_EST_MODE\"]\n",
    "    + \"-\"\n",
    "    + df[\"EVAL_MODE\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data to keep exploratory analyses tractable\n",
    "# df = df[(df[\"update\"] == 20000) & (df[\"TEST_DOWN_SAMPLE_RATE\"] == 0.5)]\n",
    "df = df[(df[\"update\"] == 20000)]\n",
    "df = df.sample(frac=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data Vectors to Long-Form\n",
    "\n",
    "i.e., each trait of each individual is a single row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_columns = (\n",
    "    #     \"genome\",\n",
    "    \"phenotype\",\n",
    "    \"traits_attempted_estimations\",\n",
    "    \"traits_estimation_dist\",\n",
    "    \"traits_estimated_scores\",\n",
    "    \"traits_estimation_source_ids\",\n",
    "    \"traits_evaluated\",\n",
    "    \"traits_successful_estimations\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in tqdm(vector_columns):\n",
    "    print(column)\n",
    "    df[column] = df[column].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vector len\"] = df[\"traits_evaluated\"].apply(len)\n",
    "for column in tqdm(vector_columns):\n",
    "    print(column)\n",
    "    assert (df[column].apply(len) == df[\"vector len\"]).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vector index\"] = df[\"vector len\"].apply(lambda x: [*range(x)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"num traits evaluated\"] = df[\"traits_evaluated\"].apply(sum)\n",
    "df[\"num attempted trait estimations\"] = df[\"traits_attempted_estimations\"].apply(sum)\n",
    "df[\"num successful trait estimations\"] = df[\"traits_successful_estimations\"].apply(sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"num successful trait estimations\"] == df[\"num attempted trait estimations\"]).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk to prevent running out of memory\n",
    "chunk_size = 32768\n",
    "num_chunks = (len(df) + chunk_size - 1) // chunk_size\n",
    "\n",
    "exploded_chunks = []\n",
    "for i in tqdm(range(num_chunks)):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min((i + 1) * chunk_size, len(df))\n",
    "    chunk = df.iloc[start_idx:end_idx]\n",
    "\n",
    "    exploded_chunk = chunk.explode([\"vector index\", *vector_columns])\n",
    "    exploded_chunks.append(exploded_chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate chunks to single csv, delete from memory, then reload from csv\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\") as tmpfile:\n",
    "    for i, exploded_chunk in enumerate(tqdm(exploded_chunks)):\n",
    "        kwargs = {\"index\": False, \"chunksize\": 4096}\n",
    "        if i:\n",
    "            kwargs[\"mode\"] = \"a\"\n",
    "            kwargs[\"header\"] = False\n",
    "        exploded_chunk.to_csv(tmpfile.name, **kwargs)\n",
    "        tmpfile.flush()\n",
    "\n",
    "    del exploded_chunks\n",
    "    exploded_df = pd.read_csv(tmpfile.name)\n",
    "\n",
    "exploded_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup New Columns needed for Analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exploded_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Trait Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"trait estimation error\"] = (\n",
    "    exploded_df[\"traits_estimated_scores\"]\n",
    "    - exploded_df[\"phenotype\"]\n",
    ")\n",
    "exploded_df[\"trait estimation abs error\"] = exploded_df[\"trait estimation error\"].abs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Trait Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_columns = [\n",
    "    \"EVAL_MODE\",\n",
    "    \"TEST_DOWN_SAMPLE_RATE\",\n",
    "    \"DIAGNOSTIC\",\n",
    "    \"EVAL_FIT_EST_MODE\",\n",
    "    \"vector index\",\n",
    "    \"update\",\n",
    "]\n",
    "exploded_df[\"normalized phenotype\"] = exploded_df.groupby(\n",
    "    groupby_columns,\n",
    ")[\"phenotype\"].rank(pct=True)\n",
    "\n",
    "\n",
    "def add_normalized_trait_estimate(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"normalized trait estimate\"] = scipy_stats.percentileofscore(\n",
    "        a=df[\"phenotype\"],\n",
    "        score=df[\"traits_estimated_scores\"],\n",
    "    ) / 100\n",
    "    return df\n",
    "exploded_df = exploded_df.groupby(\n",
    "    groupby_columns,\n",
    "    group_keys=False,\n",
    ").apply(\n",
    "    add_normalized_trait_estimate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"normalized trait estimation error\"] = (\n",
    "    exploded_df[\"normalized trait estimate\"]\n",
    "    - exploded_df[\"normalized phenotype\"]\n",
    ")\n",
    "exploded_df[\"abs normalized trait estimation error\"] = (\n",
    "    exploded_df[\"normalized trait estimation error\"].abs()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Trait Values Error %\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"normalized trait estimation error %\"] = (\n",
    "    exploded_df[\"normalized trait estimation error\"] * 100\n",
    ")\n",
    "exploded_df[\"abs normalized trait estimation error %\"] = (\n",
    "    exploded_df[\"abs normalized trait estimation error\"] * 100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trait Estimation Outcome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"is evaluated\"] = exploded_df[\"traits_evaluated\"] == 1\n",
    "exploded_df[\"is evaluated\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"is attempted estimation\"] = (\n",
    "    exploded_df[\"traits_attempted_estimations\"] == 1\n",
    ")\n",
    "exploded_df[\"is attempted estimation\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"is successful estimation\"] = (\n",
    "    exploded_df[\"traits_successful_estimations\"] == 1\n",
    ")\n",
    "exploded_df[\"is successful estimation\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"is failed estimation\"] = (\n",
    "    exploded_df[\"is attempted estimation\"]\n",
    "    & ~exploded_df[\"is successful estimation\"]\n",
    ")\n",
    "exploded_df[\"is failed estimation\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not (\n",
    "    exploded_df[\"is successful estimation\"] & exploded_df[\"is failed estimation\"]\n",
    ").any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"estimation outcome\"] = \"na\"\n",
    "exploded_df.loc[\n",
    "    exploded_df[\"is failed estimation\"],\n",
    "    \"estimation outcome\",\n",
    "] = \"failed\"\n",
    "exploded_df.loc[\n",
    "    exploded_df[\"is successful estimation\"],\n",
    "    \"estimation outcome\",\n",
    "] = \"successful\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"is evaluated and is attempted estimation\"] = (\n",
    "    exploded_df[\"is attempted estimation\"] & exploded_df[\"is evaluated\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"is neither evaluated nor attempted estimation\"] = (\n",
    "    (~exploded_df[\"is attempted estimation\"]) & (~exploded_df[\"is evaluated\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot: estimation mode vs estimation failure/attempts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catplot_bar_label(*args, **kwargs):\n",
    "    g = sns.catplot(\n",
    "        *args,\n",
    "        **kwargs,\n",
    "        margin_titles=True,\n",
    "    )\n",
    "    for ax in g.axes.flat:\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, label_type='edge')\n",
    "\n",
    "tp.tee(\n",
    "    catplot_bar_label,\n",
    "    data=exploded_df,\n",
    "    col=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    row=\"TEST_DOWN_SAMPLE_RATE\",\n",
    "    x=\"DIAGNOSTIC\",\n",
    "    hue=\"estimation outcome\",\n",
    "    kind=\"count\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    catplot_bar_label,\n",
    "    data=exploded_df,\n",
    "    col=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    row=\"DIAGNOSTIC\",\n",
    "    x=\"TEST_DOWN_SAMPLE_RATE\",\n",
    "    y=\"is evaluated\",\n",
    "    kind=\"bar\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    catplot_bar_label,\n",
    "    data=exploded_df,\n",
    "    col=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    row=\"DIAGNOSTIC\",\n",
    "    x=\"TEST_DOWN_SAMPLE_RATE\",\n",
    "    y=\"is evaluated and is attempted estimation\",\n",
    "    kind=\"bar\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    catplot_bar_label,\n",
    "    data=exploded_df,\n",
    "    col=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    row=\"DIAGNOSTIC\",\n",
    "    x=\"TEST_DOWN_SAMPLE_RATE\",\n",
    "    y=\"is neither evaluated nor attempted estimation\",\n",
    "    kind=\"bar\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    catplot_bar_label,\n",
    "    data=exploded_df,\n",
    "    col=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    row=\"DIAGNOSTIC\",\n",
    "    x=\"TEST_DOWN_SAMPLE_RATE\",\n",
    "    y=\"is attempted estimation\",\n",
    "    kind=\"bar\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot: estimated score vs phenotype\n",
    "\n",
    "by diagnostic and estimate mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_scatterplot(data, col, row, x, y):\n",
    "    g = sns.FacetGrid(\n",
    "        data=data,\n",
    "        col=col,\n",
    "        row=row,\n",
    "        margin_titles=True,\n",
    "    )\n",
    "    g.map(\n",
    "        sns.scatterplot,\n",
    "        x,\n",
    "        y,\n",
    "    )\n",
    "\n",
    "tp.tee(\n",
    "    facet_scatterplot,\n",
    "    data=exploded_df[\n",
    "        exploded_df[\"is successful estimation\"]\n",
    "    ],\n",
    "    col=\"DIAGNOSTIC\",\n",
    "    row=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    x=\"phenotype\",\n",
    "    y=\"traits_estimated_scores\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot: trait estimation error vs phylogenetic distance\n",
    "\n",
    "for each diagnostic and estimation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_regplot(data, x, y, col, row):\n",
    "    g = sns.FacetGrid(\n",
    "        data=data,\n",
    "        col=col,\n",
    "        row=row,\n",
    "        margin_titles=True,\n",
    "        sharex=False,\n",
    "        sharey=\"row\",\n",
    "    )\n",
    "    g.map(\n",
    "        sns.regplot,\n",
    "        x,\n",
    "        y,\n",
    "        n_boot=10,\n",
    "        scatter_kws={\n",
    "            \"color\": \"red\",\n",
    "            \"alpha\": 0.1,\n",
    "        },\n",
    "    ).set(\n",
    "        xscale=\"log\",\n",
    "        yscale=\"log\",\n",
    "    )\n",
    "\n",
    "tp.tee(\n",
    "    facet_regplot,\n",
    "    data=exploded_df[\n",
    "        exploded_df[\"is successful estimation\"]\n",
    "        & (exploded_df[\"traits_estimation_dist\"] > 0)\n",
    "    ],\n",
    "    col=\"DIAGNOSTIC\",\n",
    "    row=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    x=\"traits_estimation_dist\",\n",
    "    y=\"abs normalized trait estimation error\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symlog(x, linthresh=1):\n",
    "    if linthresh <= 0:\n",
    "        raise ValueError(\"linthresh should be positive\")\n",
    "\n",
    "    x_abs = np.abs(x)\n",
    "    sign = np.sign(x)\n",
    "\n",
    "    log_part = np.log10(x_abs - linthresh + 1) * (x_abs > linthresh)\n",
    "    lin_part = x * (x_abs <= linthresh)\n",
    "\n",
    "    return sign * (log_part + lin_part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symlog_formatter(x, pos):\n",
    "    sign = '-' if x < 0 else ''\n",
    "    x_abs = abs(x)\n",
    "    return f'{sign}$10^{{{x_abs}}}$' if x else \"0\"\n",
    "\n",
    "def facet_histplot(data, x, y, hue, col, row):\n",
    "    g = sns.FacetGrid(\n",
    "        data=data,\n",
    "        col=col,\n",
    "        row=row,\n",
    "        margin_titles=True,\n",
    "        sharex=True,\n",
    "        sharey=\"row\",\n",
    "        aspect=1,\n",
    "    )\n",
    "    g.map(\n",
    "        sns.histplot,\n",
    "        x,\n",
    "        y,\n",
    "        hue,\n",
    "        binwidth=(1, 0.1),\n",
    "        palette=sns.color_palette([\"blue\"]),\n",
    "        common_norm=False,\n",
    "    ).set_axis_labels(\n",
    "        x_var=\"Log2 Estimation Distance\",\n",
    "        y_var=\"Trait Estimate Error,\\nNormalized %\",\n",
    "    ).set_titles(\n",
    "        col_template=\"{col_var}\\n{col_name}\",\n",
    "        row_template=\"MODE\\n{row_name}\",\n",
    "    )\n",
    "\n",
    "    # Create a FuncFormatter instance with the custom function\n",
    "    formatter = mpl_FuncFormatter(symlog_formatter)\n",
    "    for ax in g.axes.flat:\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "# tp.tee(\n",
    "#     sns.displot,\n",
    "exploded_df[\"log2 traits_estimation_dist\"] = np.log2(exploded_df[\"traits_estimation_dist\"])\n",
    "exploded_df[\"symlog normalized trait estimation error %\"] = symlog(exploded_df[\"normalized trait estimation error %\"])\n",
    "\n",
    "tp.tee(\n",
    "    facet_histplot,\n",
    "    data=exploded_df[\n",
    "        exploded_df[\"is successful estimation\"]\n",
    "        & (exploded_df[\"traits_estimation_dist\"] > 0)\n",
    "    ],\n",
    "    col=\"DIAGNOSTIC\",\n",
    "    row=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    x=\"log2 traits_estimation_dist\",\n",
    "    y=\"symlog normalized trait estimation error %\",\n",
    "    hue=\"log2 traits_estimation_dist\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_histplot(data, x, y, hue, col, row):\n",
    "    g = sns.FacetGrid(\n",
    "        data=data,\n",
    "        col=col,\n",
    "        row=row,\n",
    "        margin_titles=True,\n",
    "        sharex=True,\n",
    "        sharey=\"row\",\n",
    "        aspect=1,\n",
    "    )\n",
    "    g.map(\n",
    "        sns.histplot,\n",
    "        x,\n",
    "        y,\n",
    "        hue,\n",
    "        binwidth=(1, 0.1),\n",
    "        palette=sns.color_palette([\"blue\"]),\n",
    "        common_norm=False,\n",
    "    ).set_axis_labels(\n",
    "        x_var=\"Log2 Estimation Distance\",\n",
    "        y_var=\"Trait Estimate Error,\\nAbs Normalized %\",\n",
    "    ).set_titles(\n",
    "        col_template=\"{col_var}\\n{col_name}\",\n",
    "        row_template=\"MODE\\n{row_name}\",\n",
    "    )\n",
    "\n",
    "    # Create a FuncFormatter instance with the custom function\n",
    "    formatter = mpl_FuncFormatter(symlog_formatter)\n",
    "    for ax in g.axes.flat:\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "exploded_df[\"log2 traits_estimation_dist\"] = np.log2(exploded_df[\"traits_estimation_dist\"])\n",
    "exploded_df[\"symlog abs normalized trait estimation error %\"] = symlog(exploded_df[\"abs normalized trait estimation error %\"])\n",
    "tp.tee(\n",
    "    facet_histplot,\n",
    "    data=exploded_df[\n",
    "        exploded_df[\"is successful estimation\"]\n",
    "        & (exploded_df[\"traits_estimation_dist\"] > 0)\n",
    "    ],\n",
    "    col=\"DIAGNOSTIC\",\n",
    "    row=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    x=\"log2 traits_estimation_dist\",\n",
    "    y=\"symlog abs normalized trait estimation error %\",\n",
    "    hue=\"log2 traits_estimation_dist\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot: mean estimation error by diagnostic/estimation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_barplot(data, x, y, row, col):\n",
    "    g = sns.FacetGrid(\n",
    "        data=data,\n",
    "        row=row,\n",
    "        col=col,\n",
    "        margin_titles=True,\n",
    "        sharey=\"row\",\n",
    "        sharex=False,\n",
    "    )\n",
    "    g.map(\n",
    "        sns.barplot,\n",
    "        x,\n",
    "        y,\n",
    "    )\n",
    "\n",
    "tp.tee(\n",
    "    facet_barplot,\n",
    "    data=exploded_df[\n",
    "        exploded_df[\"is successful estimation\"]\n",
    "        & (exploded_df[\"traits_estimation_dist\"] > 0)\n",
    "    ],\n",
    "    x=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    y=\"trait estimation abs error\",\n",
    "    row=\"DIAGNOSTIC\",\n",
    "    col=\"TEST_DOWN_SAMPLE_RATE\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet_barplot(\n",
    "    data=exploded_df[\n",
    "        exploded_df[\"is successful estimation\"]\n",
    "        & (exploded_df[\"traits_estimation_dist\"] > 0)\n",
    "    ],\n",
    "    x=\"EVAL_FIT_EST_MODE\",\n",
    "    y=\"abs normalized trait estimation error\",\n",
    "    col=\"DIAGNOSTIC\",\n",
    "    row=\"TEST_DOWN_SAMPLE_RATE\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet_barplot(\n",
    "    data=exploded_df[\n",
    "        exploded_df[\"is successful estimation\"]\n",
    "        & (exploded_df[\"traits_estimation_dist\"] > 0)\n",
    "    ],\n",
    "    x=\"EVAL_FIT_EST_MODE\",\n",
    "    y=\"abs normalized trait estimation error\",\n",
    "    col=\"DIAGNOSTIC\",\n",
    "    row=\"TEST_DOWN_SAMPLE_RATE\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalized, not absolute value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet_barplot(\n",
    "    data=exploded_df[\n",
    "        exploded_df[\"is successful estimation\"]\n",
    "        & (exploded_df[\"traits_estimation_dist\"] > 0)\n",
    "    ],\n",
    "    x=\"EVAL_FIT_EST_MODE\",\n",
    "    y=\"normalized trait estimation error\",\n",
    "    col=\"DIAGNOSTIC\",\n",
    "    row=\"TEST_DOWN_SAMPLE_RATE\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot: phylogenetic estimation distance by diagnostic/estimation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_barplot,\n",
    "    data=exploded_df[\n",
    "        exploded_df[\"is successful estimation\"]\n",
    "        & (exploded_df[\"traits_estimation_dist\"] > 0)\n",
    "    ],\n",
    "    row=\"DIAGNOSTIC\",\n",
    "    col=\"TEST_DOWN_SAMPLE_RATE\",\n",
    "    x=\"EVAL_FIT_EST_MODE\",\n",
    "    y=\"traits_estimation_dist\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot: error distributions\n",
    "\n",
    "by diagnostic/evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facet_violinplot(data, x, y, col, row):\n",
    "    g = sns.FacetGrid(\n",
    "        data=data,\n",
    "        col=col,\n",
    "        row=row,\n",
    "        margin_titles=True,\n",
    "        sharex=False,\n",
    "    )\n",
    "    g.map(\n",
    "        sns.violinplot,\n",
    "        x,\n",
    "        y,\n",
    "    )\n",
    "\n",
    "tp.tee(\n",
    "    facet_violinplot,\n",
    "    data=exploded_df[exploded_df[\"is successful estimation\"]],\n",
    "    x=\"trait estimation abs error\",\n",
    "    y=\"EVAL_FIT_EST_MODE-EVAL_MODE\",\n",
    "    col=\"DIAGNOSTIC\",\n",
    "    row=\"TEST_DOWN_SAMPLE_RATE\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    facet_violinplot,\n",
    "    data=exploded_df[exploded_df[\"is successful estimation\"]],\n",
    "    x=\"abs normalized trait estimation error\",\n",
    "    y=\"EVAL_FIT_EST_MODE\",\n",
    "    col=\"DIAGNOSTIC\",\n",
    "    row=\"TEST_DOWN_SAMPLE_RATE\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_columns = [\n",
    "    \"EVAL_MODE\",\n",
    "    \"TEST_DOWN_SAMPLE_RATE\",\n",
    "    \"DIAGNOSTIC\",\n",
    "    \"EVAL_FIT_EST_MODE\",\n",
    "    \"update\",\n",
    "]\n",
    "records = []\n",
    "for group, group_df in exploded_df.groupby(groupby_columns):\n",
    "    group_attrs = dict(zip(groupby_columns, group))\n",
    "    res = scipy_stats.spearmanr(\n",
    "        group_df[\"trait estimation abs error\"],\n",
    "        group_df[\"traits_estimation_dist\"],\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            **group_attrs,\n",
    "            **{\n",
    "                \"error vs. dist spearmanr correlation statistic\" : res.statistic,\n",
    "                \"error vs. dist spearmanr correlation p\" : res.pvalue,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_columns = [\n",
    "    \"EVAL_MODE\",\n",
    "    \"TEST_DOWN_SAMPLE_RATE\",\n",
    "    \"DIAGNOSTIC\",\n",
    "    \"EVAL_FIT_EST_MODE\",\n",
    "    \"update\",\n",
    "]\n",
    "records = []\n",
    "for group, group_df in tqdm(exploded_df.groupby(groupby_columns)):\n",
    "    group_attrs = dict(zip(groupby_columns, group))\n",
    "    data = group_df[\"normalized trait estimation error\"]\n",
    "    records.append(\n",
    "        {\n",
    "            **group_attrs,\n",
    "            **{\n",
    "                \"mean normalized error\" : data.mean(),\n",
    "                \"median normalized error\" : data.median(),\n",
    "                \"1st percentile normalized error\" : scipy_stats.scoreatpercentile(data, 1),\n",
    "                \"5th percentile normalized error\" : scipy_stats.scoreatpercentile(data, 5),\n",
    "                \"95th percentile normalized error\" : scipy_stats.scoreatpercentile(data, 95),\n",
    "                \"99th percentile normalized error\" : scipy_stats.scoreatpercentile(data, 99),\n",
    "            },\n",
    "#             **dict(\n",
    "#                 zip(\n",
    "#                     (\"95% CI lower bound\", \"95% CI upper bound\"),\n",
    "#                     scipy_stats.bootstrap(\n",
    "#                         (data,),\n",
    "#                         np.mean,\n",
    "#                         batch=9,\n",
    "#                         n_resamples=9,\n",
    "#                     ).confidence_interval,\n",
    "#                 )\n",
    "#             ),\n",
    "#             **dict(\n",
    "#                 zip(\n",
    "#                     (\"99% CI lower bound\", \"99% CI upper bound\"),\n",
    "#                     scipy_stats.bootstrap(\n",
    "#                         (data,),\n",
    "#                         np.mean,\n",
    "#                         batch=9,\n",
    "#                         n_resamples=9,\n",
    "#                         confidence_level=0.99,\n",
    "#                     ).confidence_interval,\n",
    "#                 )\n",
    "#             )\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_columns = [\n",
    "    \"EVAL_MODE\",\n",
    "    \"TEST_DOWN_SAMPLE_RATE\",\n",
    "    \"DIAGNOSTIC\",\n",
    "    \"EVAL_FIT_EST_MODE\",\n",
    "    \"update\",\n",
    "]\n",
    "records = []\n",
    "for group, group_df in tqdm(exploded_df.groupby(groupby_columns)):\n",
    "    group_attrs = dict(zip(groupby_columns, group))\n",
    "    data = group_df[\"abs normalized trait estimation error\"]\n",
    "    records.append(\n",
    "        {\n",
    "            **group_attrs,\n",
    "            **{\n",
    "                \"mean normalized absolute error\" : data.mean(),\n",
    "                \"median normalized absolute error\" : data.median(),\n",
    "                \"1st percentile normalized absolute error\" : scipy_stats.scoreatpercentile(data, 1),\n",
    "                \"5th percentile normalized absolute error\" : scipy_stats.scoreatpercentile(data, 5),\n",
    "                \"95th percentile normalized absolute error\" : scipy_stats.scoreatpercentile(data, 95),\n",
    "                \"99th percentile normalized absolute error\" : scipy_stats.scoreatpercentile(data, 99),\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df[\"is failed estimation\"].any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_columns = [\n",
    "    \"EVAL_MODE\",\n",
    "    \"TEST_DOWN_SAMPLE_RATE\",\n",
    "    \"EVAL_FIT_EST_MODE\",\n",
    "    \"update\",\n",
    "]\n",
    "records = []\n",
    "for group, group_df in tqdm(exploded_df.groupby(groupby_columns)):\n",
    "    group_attrs = dict(zip(groupby_columns, group))\n",
    "    stat, p_value = scipy_stats.kruskal(\n",
    "        *dict([*group_df.groupby(\"DIAGNOSTIC\")[\"abs normalized trait estimation error\"]]).values()\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            **group_attrs,\n",
    "            **{\n",
    "                \"normalized error by diagnostic kruskal-wallis p value\" : p_value,\n",
    "                \"normalized error by diagnostic kruskal-wallis statistic\" : stat,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_columns = [\n",
    "    \"EVAL_MODE\",\n",
    "    \"TEST_DOWN_SAMPLE_RATE\",\n",
    "    \"EVAL_FIT_EST_MODE\",\n",
    "    \"update\",\n",
    "]\n",
    "\n",
    "records = []\n",
    "\n",
    "for group, group_df in tqdm(exploded_df.groupby(groupby_columns)):\n",
    "    group_attrs = dict(zip(groupby_columns, group))\n",
    "    diagnostic_groups = dict([*group_df.groupby(\"DIAGNOSTIC\")[\"abs normalized trait estimation error\"]])\n",
    "\n",
    "    pairwise_comparisons = [*it.combinations(diagnostic_groups.keys(), 2)]\n",
    "    p_values = []\n",
    "    for first_diagnostic, second_diagnostic in pairwise_comparisons:\n",
    "        stat, p_value = scipy_stats.mannwhitneyu(\n",
    "            diagnostic_groups[first_diagnostic],\n",
    "            diagnostic_groups[second_diagnostic],\n",
    "            alternative='two-sided',\n",
    "        )\n",
    "        p_values.append(p_value)\n",
    "\n",
    "    # Apply Bonferroni correction\n",
    "    corrected_p_values = statsmodels_stats.multitest.multipletests(\n",
    "        p_values, method='bonferroni'\n",
    "    )[1]\n",
    "\n",
    "    for (\n",
    "        (first_diagnostic, second_diagnostic),\n",
    "        p_value,\n",
    "        corrected_p_value,\n",
    "    ) in zip(pairwise_comparisons, p_values, corrected_p_values):\n",
    "        if np.median(diagnostic_groups[first_diagnostic]) < np.median(diagnostic_groups[second_diagnostic]):\n",
    "            lower_error_diagnostic = first_diagnostic\n",
    "            higher_error_diagnostic = second_diagnostic\n",
    "        else:\n",
    "            lower_error_diagnostic = second_diagnostic\n",
    "            higher_error_diagnostic = first_diagnostic\n",
    "\n",
    "        records.append(\n",
    "            {\n",
    "                **group_attrs,\n",
    "                \"lower error diagnostic\": lower_error_diagnostic,\n",
    "                \"higher error diagnostic\": higher_error_diagnostic,\n",
    "                \"p value\": p_value,\n",
    "                \"corrected p value\": corrected_p_value,\n",
    "            }\n",
    "        )\n",
    "\n",
    "pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_columns = [\n",
    "    \"EVAL_MODE\",\n",
    "    \"DIAGNOSTIC\",\n",
    "    \"EVAL_FIT_EST_MODE\",\n",
    "    \"update\",\n",
    "]\n",
    "records = []\n",
    "for group, group_df in tqdm(exploded_df.groupby(groupby_columns)):\n",
    "    try:\n",
    "        group_attrs = dict(zip(groupby_columns, group))\n",
    "        stat, p_value = scipy_stats.kruskal(\n",
    "            *dict([*group_df.groupby(\"TEST_DOWN_SAMPLE_RATE\")[\"abs normalized trait estimation error\"]]).values()\n",
    "        )\n",
    "        records.append(\n",
    "            {\n",
    "                **group_attrs,\n",
    "                **{\n",
    "                    \"normalized error by diagnostic kruskal-wallis p value\" : p_value,\n",
    "                    \"normalized error by diagnostic kruskal-wallis statistic\" : stat,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    except ValueError:\n",
    "        # due to apparent bug in ancestor 0.2 fit est mode name\n",
    "        continue\n",
    "\n",
    "pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_columns = [\n",
    "    \"EVAL_MODE\",\n",
    "    \"DIAGNOSTIC\",\n",
    "    \"EVAL_FIT_EST_MODE\",\n",
    "    \"update\",\n",
    "]\n",
    "\n",
    "records = []\n",
    "\n",
    "for group, group_df in tqdm(exploded_df.groupby(groupby_columns)):\n",
    "    try:\n",
    "        group_attrs = dict(zip(groupby_columns, group))\n",
    "        downsample_groups = dict([*group_df.groupby(\"TEST_DOWN_SAMPLE_RATE\")[\"abs normalized trait estimation error\"]])\n",
    "\n",
    "        pairwise_comparisons = [*it.combinations(downsample_groups.keys(), 2)]\n",
    "        p_values = []\n",
    "        for first_downsample, second_downsample in pairwise_comparisons:\n",
    "            stat, p_value = scipy_stats.mannwhitneyu(\n",
    "                downsample_groups[first_downsample],\n",
    "                downsample_groups[second_downsample],\n",
    "                alternative='two-sided',\n",
    "            )\n",
    "            p_values.append(p_value)\n",
    "\n",
    "        # Apply Bonferroni correction\n",
    "        corrected_p_values = statsmodels_stats.multitest.multipletests(\n",
    "            p_values, method='bonferroni',\n",
    "        )[1]\n",
    "\n",
    "        for (\n",
    "            (first_downsample, second_downsample),\n",
    "            p_value,\n",
    "            corrected_p_value,\n",
    "        ) in zip(pairwise_comparisons, p_values, corrected_p_values):\n",
    "            if np.median(downsample_groups[first_downsample]) < np.median(downsample_groups[second_downsample]):\n",
    "                lower_error_downsample = first_downsample\n",
    "                higher_error_downsample = second_downsample\n",
    "            else:\n",
    "                lower_error_downsample = second_downsample\n",
    "                higher_error_downsample = first_downsample\n",
    "\n",
    "            records.append(\n",
    "                {\n",
    "                    **group_attrs,\n",
    "                    \"lower error downsample\": lower_error_downsample,\n",
    "                    \"higher error downsample\": higher_error_downsample,\n",
    "                    \"p value\": p_value,\n",
    "                    \"corrected p value\": corrected_p_value,\n",
    "                }\n",
    "            )\n",
    "    except (ValueError, ZeroDivisionError):\n",
    "        # due to apparent bug in ancestor 0.2 fit est mode name\n",
    "        pass\n",
    "\n",
    "pd.DataFrame.from_records(records)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
